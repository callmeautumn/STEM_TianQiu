{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEM for Creatives Week 6  - Images\n",
    "\n",
    "### Pixels\n",
    "\n",
    "As we saw with audio, when we break media down on computers, they are just multi-dimensional arrays. Whilst audio is often 1-dimensional (or more for multi-channel audio), images have more components to them. \n",
    "\n",
    "Whilst digital audio is made up of **samples**, digital images are made up of **pixels**. When we are dealing with black and white images (often known as **grayscale**), each image is a **2D array**, which each dimension relating to \n",
    "\n",
    "- row (height)\n",
    "- column (width)\n",
    "\n",
    "Each item in this array represents a pixel and its number tells us where on the scale of black (low) to white (high) it is. We can use different types of numbers to represent ecah pixel but often the scale is 0 - 255.\n",
    "\n",
    "### PIL (Python Imaging Library)\n",
    "\n",
    "We can use PIL to import and display images, and then turn them into **NumPy** arrays. And we know how to do things with them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pillow scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#This is actually a colour image, so we make it grayscale to begin with (convert('L'))\n",
    "im = np.array(Image.open('images/robot-enstein.jpg').convert('L'))\n",
    "Image.fromarray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How big is it?\n",
    "h = im.shape[0]\n",
    "w = im.shape[1]\n",
    "print(w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at pixels\n",
    "#Gives us the grayscale of a particular pixel \n",
    "print(im[12,45])\n",
    "#Pixel in the middle\n",
    "mid_y = int(h/2)\n",
    "mid_x = int(w/2)\n",
    "print(im[mid_y,mid_x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour (RGB)\n",
    "\n",
    "Sure grayscale is good, but have you tried colour? In the RGB representation an image is made up of three channels\n",
    "\n",
    "- **R**ed\n",
    "- **G**reen \n",
    "- **B**lue \n",
    "\n",
    "So in a way its actually like 3 images, that combine together to make the full colour output. We can get all colours from combinations of these three base colours.\n",
    "\n",
    "### Colour Channels\n",
    "\n",
    "So how does effect our NumPy array? We end up with a **3D array**, whose dimensions map to \n",
    "\n",
    "- row (height)\n",
    "- column (width)\n",
    "- color (channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.array(Image.open('images/robot-enstein.jpg'))\n",
    "Image.fromarray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the size and number of channels\n",
    "h = im.shape[0]\n",
    "w = im.shape[1]\n",
    "c = im.shape[2]\n",
    "print(w, h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at pixels\n",
    "#Gives us the RGB of a particular pixel -> We get three values for each one!\n",
    "print(im[12,45])\n",
    "#Pixel in the middle\n",
    "print(im[mid_y,mid_x-60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Pixel Values\n",
    "\n",
    "As well as looking at pixel values, we can also set them to new things. We can do this by just changing the values in the arrays, just like we did with audio files. \n",
    "\n",
    "When we change the file, like we did with the audio, we first make a copy. This way the original image file stays unaltered so we can use it again  \n",
    "\n",
    "```\n",
    "new_image = im.copy()\n",
    "```\n",
    "\n",
    "#### Tuples\n",
    "\n",
    "We can do this to single pixels, or groups of pixels. Each pixel is actually represented as a **tuple**. Tuples are single objects that hold mutiple values and are a **collection which is ordered and unchangeable**. This means we can access the items inside with indexes (because its ordered), but we cant change them (because they're unchangeable).\n",
    "\n",
    "Tuples are written, and created, with **round brackets**\n",
    "\n",
    "```\n",
    "a = (1,2,3,4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set the middle pixel to full red (RGB). Look reeeeal closely.\n",
    "new_image = im.copy()\n",
    "new_image[mid_y,mid_x] = (255,0,0)\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Photo Mosaic \n",
    "\n",
    "Next we will build up some code you to create a photomosaic. \n",
    "\n",
    "A chosen image will get reconstructed using a seperate dataset of images that you specify. These images are used for the tiles in the photomosaic, and they are selected based on image with the closest mean colour to the target pixel. \n",
    "\n",
    "The code here is a modified version of code from this repository: https://github.com/MstrFunkBass/facemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import random\n",
    "from mosaic import get_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Downsampling\n",
    "\n",
    "First we need to downsample the source image so it has less pixels. As our plan is swap each source pixel for a matching image from the dataset, it is in our interest to have less of them! \n",
    "\n",
    "To do this, we will just skip pixels at regular intervals. This does lose some information, but is really efficient and turns out to work fine for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip indexing \n",
    "\n",
    "``array(start,end,step)``\n",
    "\n",
    "Here we use the code ``source[::skip,::skip]`` to say \"Get me all of the pixels, skipping at a given interval.\n",
    "\n",
    "Play with the `skip` variable to see the effects of different down sampling. The display in the notebook is not quite accurate however. As we downsample, we are making smaller images (less pixels). To display we have sclaed back up to the original size so it looks more like a **blur** than a **downsample**. If you look at the actual file `scaled.png`, you will see a much more blocky image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Drop the 4th alpha channel we get the a .png\n",
    "source = np.array(Image.open('images/cat_meme.png'))[:,:,:3]\n",
    "skip = 20\n",
    "mosaic_template = source[::skip,::skip]\n",
    "Image.fromarray(mosaic_template).save('scaled.png')\n",
    "print(mosaic_template.shape)\n",
    "IPython.display.Image('scaled.png',width=source.shape[1]//2,height=source.shape[0]//2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Getting a dataset\n",
    "\n",
    "We have some code which walks through a file and finds and the images, scales them all to the same size (and smaller) and stores them in a dataset. If you want to see how this works, look in the file `mosaic.py`\n",
    "\n",
    "Here is the code for loading the dataset of images. First you will need to [download this file](https://artslondon-my.sharepoint.com/:u:/g/personal/t_broad_arts_ac_uk/EaQZzKGUebZMkn_nAHX1VLUBKS4tYSuOqUOH_0BVUSjanA?e=u9W8PI), unzip it, then put it into the `data` folder.\n",
    "\n",
    "This is a dataset of [images of animals from kaggle](https://www.kaggle.com/datasets/iamsouravbanerjee/animal-image-dataset-90-different-animals) that have been resized into thumbnails (for faster download and processing). The full dataset should contain 5400 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail_size = (50,50)\n",
    "dataset = get_images(\"data/animal_thumbnails/land_mammals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images x width x height x channels\n",
    "print(dataset.shape)\n",
    "Image.fromarray(dataset[random.randint(0,len(dataset))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Find Average Colour Of Each Image\n",
    "\n",
    "To help us find which image from the dataset should replace each pixel in the source, we are going to find out what the **average red, green and blue** values are for each image. We need to do this for each channel to maintain the colour information. We will then use this to match to the **red, green and blue** values of each pixel in the downsampled source image.\n",
    "\n",
    "#### `np.apply_over_axes()`\n",
    "\n",
    "We we will us a ``numpy`` function called ``apply_over_axes()`` to apply our `np.mean` function to only certain channels of our 4d array.\n",
    "\n",
    "If we did `np.mean()` to the whole dataset, we'd just get one value! \n",
    "\n",
    "We can get the average of all the images in our dataset by applying it to the `first axis [0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_values = np.apply_over_axes(np.mean, dataset, [0]).astype(np.uint8)\n",
    "Image.fromarray(image_values[0]).save('mean_cat.png')\n",
    "IPython.display.Image('mean_cat.png',width=400,height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what we actually want is to apply it to the second and third axes. This averages the pixel information over the `width` and `height`, but maintains the separation of `images` and `channels`. \n",
    "\n",
    "We end up with an array that is `images x 1 x 1 x channels`. We can use `np.reshape` to remove those two in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rgb_dataset = np.apply_over_axes(np.mean, dataset, [1,2])\n",
    "print(mean_rgb_dataset.shape)\n",
    "mean_rgb_dataset = mean_rgb_dataset.reshape(len(dataset), 3)\n",
    "print(mean_rgb_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Match Images to Pixels\n",
    "\n",
    "Next we have to do the matching! We will use `binary tree search` to do this efficiently, no need to know how this works in detail. \n",
    "\n",
    "We build a `tree` from the `mean_rgb_dataset`, and then `query()` with each pixel from the source to get the `k` closest matches. We then randomly pick one and save the index of the matched image for building the mosaic in the next step.\n",
    "\n",
    "#### Nested `for loops`\n",
    "\n",
    "Last week we saw how to use `for loops` to iterate over a `1D list` (e.g. an audio file). This enabled us to write one piece of code that got applied to each window of audio in turn.\n",
    "\n",
    "Images can be seen as `2D lists`, so we can actually use 2 `for loops` to write code to address each pixel in turn! One `for loop` is `nested` inside the other. \n",
    "\n",
    "The code below first starts on the top row, then the second `for loop` loops over each column. When it has done each column in the first row, the second loop is over and the first loop then moves onto the second row. We then move through each column again, until we have done all the rows.\n",
    "\n",
    "```\n",
    "for row in range(w):\n",
    "    for col in range(h):\n",
    "        pixel = mosaic_template[row, col]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the search tree\n",
    "tree = spatial.KDTree(mean_rgb_dataset)\n",
    "\n",
    "#Variables to store which image is assigned to which pixel\n",
    "mosaic_template = np.swapaxes(mosaic_template,0,1)\n",
    "w,h = mosaic_template.shape[0:2]\n",
    "matched_images = np.zeros((w,h), dtype=np.uint32)\n",
    "#Go through each pixel and find the closest matching thumbnail image by mean colour and assign the index into the 2D array\n",
    "k = 40\n",
    "for row in range(w):\n",
    "    for col in range(h):\n",
    "        pixel = mosaic_template[row, col]\n",
    "        #Get the match\n",
    "        match = tree.query(pixel, k=k)\n",
    "        pick = random.randint(0, k-1)\n",
    "        matched_images[row, col] = match[1][pick]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Build the Mosaic\n",
    "\n",
    "Now we need to stitch all those matched images together into our mosaic. Again a `nested for loop` is useful to work through our `2D data` (again, the pixels of the source image). \n",
    "\n",
    "For each pixel, we retrieve the index of the match from `matched_images`. We then get the original thumbnail and `paste()` it into the right grid square on our `mosaic`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable that can contail all the pixel values for the new image\n",
    "mosaic = Image.new('RGB', (thumbnail_size[0]*w, thumbnail_size[1]*h))\n",
    "\n",
    "#Go through each pixel in the array of thumbnail<>pixel indexes and then assign all the pixels of the thumbnail into the final array\n",
    "for i in range(w):\n",
    "    for j in range(h):\n",
    "        matched_image = dataset[matched_images[i, j],:,:,:]\n",
    "        #Coordinates to place the thumbnail\n",
    "        x, y = i*thumbnail_size[0], j*thumbnail_size[1]\n",
    "        im = Image.fromarray(matched_image)\n",
    "        mosaic.paste(im, (x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the photomosaic to a file\n",
    "mosaic.save('mosaic.png')\n",
    "\n",
    "#Display the photomosaic in the notebook\n",
    "display(mosaic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
